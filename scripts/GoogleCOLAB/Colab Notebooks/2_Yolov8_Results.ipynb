{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Kr3UpMThpLkakcDo9WF2Et_aykt8kiyA","timestamp":1678372670012},{"file_id":"1kyupHqZ1B7bfRx1fiZxmYnScs2x70iv-","timestamp":1678281957175},{"file_id":"1wjyDSxjX3_mepCxGe8SyKhiL4rK5nARV","timestamp":1678281842488}],"mount_file_id":"1wjyDSxjX3_mepCxGe8SyKhiL4rK5nARV","authorship_tag":"ABX9TyO1Y5KdZr7PvoKL4aK4pDiP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["**Install the necessary libraries**"],"metadata":{"id":"-fXnthNIzfVl"}},{"cell_type":"code","source":["# Pip install method (recommended)\n","\n","!pip install ultralytics\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","from ultralytics import YOLO\n","ultralytics.checks()\n","\n","import os\n","from google.colab import drive\n","import cv2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQQl-yeG6o8A","executionInfo":{"status":"ok","timestamp":1678373328270,"user_tz":-60,"elapsed":14935,"user":{"displayName":"ahp1","userId":"09544821653816091806"}},"outputId":"ffaf1cf4-37cd-484b-ae3c-f8a17235d656"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.51 ðŸš€ Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 25.4/78.2 GB disk)\n"]}]},{"cell_type":"markdown","source":["**Mount your Google Drive (Permit and trust)**"],"metadata":{"id":"g4GGw2cizxMJ"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ike2KVS03hM3","executionInfo":{"status":"ok","timestamp":1678373353977,"user_tz":-60,"elapsed":25713,"user":{"displayName":"ahp1","userId":"09544821653816091806"}},"outputId":"93e170f2-3920-4ce2-92e6-de76bfe9e766"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["MOUNTPOINT = '/content/gdrive'\n","DATADIR = os.path.join(MOUNTPOINT, 'My Drive', 'Colab Notebooks')\n","drive.mount(MOUNTPOINT)"]},{"cell_type":"markdown","source":["**Check acces and the content of your google drive**"],"metadata":{"id":"yJQLTfz0z7Fe"}},{"cell_type":"code","source":["print(\"Files and folders: \", os.listdir(DATADIR))\n","print(\"Full path: \", DATADIR)"],"metadata":{"id":"6xnOHpGC-FCM","executionInfo":{"status":"ok","timestamp":1678373357739,"user_tz":-60,"elapsed":4,"user":{"displayName":"ahp1","userId":"09544821653816091806"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0d92fbb-09ac-450a-b8f5-45d9e96217ef"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Files and folders:  ['datasets', 'test_img.jpg', 'predict.jpg', '0_yolov8_FirstSteps.ipynb', '1_Yolov8_Train.ipynb', '2_Yolov8_Results.ipynb']\n","Full path:  /content/gdrive/My Drive/Colab Notebooks\n"]}]},{"cell_type":"markdown","source":["**Load the model from custom training (transfer learning)**"],"metadata":{"id":"v4OCbEx10G4s"}},{"cell_type":"code","source":["# Load a model\n","model = YOLO(\"/content/gdrive/My Drive/Colab Notebooks/datasets/hennen/runs/train/weights/best.pt\")  \n","\n","# Use the model\n","results = model(\"/content/gdrive/My Drive/Colab Notebooks/datasets/hennen/test/images/AviForum_Hennen_608x608 014.jpg\")  # predict on an image\n","\n","# Save the results\n","res_plotted = results[0].plot()\n","cv2.imwrite(\"/content/gdrive/My Drive/Colab Notebooks/predict_henne.jpg\", res_plotted)"],"metadata":{"id":"ALAHlBaJ0Lgr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678373448420,"user_tz":-60,"elapsed":4170,"user":{"displayName":"ahp1","userId":"09544821653816091806"}},"outputId":"748756e7-9bc2-4100-c43b-4ab15455e180"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/gdrive/My Drive/Colab Notebooks/datasets/hennen/test/images/AviForum_Hennen_608x608 014.jpg: 608x608 34 hennes, 2 henneGPSs, 11.3ms\n","Speed: 0.7ms preprocess, 11.3ms inference, 41.8ms postprocess per image at shape (1, 3, 608, 608)\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]}]}